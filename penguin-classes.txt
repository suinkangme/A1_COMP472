**************************************************************
(A) Classifier 1 - Base DT
DecisionTreeClassifier()


(B) Confusion Matrix
[[36  0  1]
 [ 3 17  0]
 [ 0  0 27]]


(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.92      0.97      0.95        37
      Gentoo       1.00      0.85      0.92        20
    Chinstap       0.96      1.00      0.98        27

    accuracy                           0.95        84
   macro avg       0.96      0.94      0.95        84
weighted avg       0.95      0.95      0.95        84


(E) The result after 5 times of train-test repetition:
average accuracy: 0.9690, variance: 0.000374
average macro-average F1: 0.9637, variance: 0.000532
average weighted-average F1: 0.9689, variance: 0.000373




**************************************************************
(A) Classifier 2 - Top DT
GridSearchCV(estimator=DecisionTreeClassifier(),
             param_grid={'criterion': ['gini', 'entropy'],
                         'max_depth': [None, 3, 5],
                         'min_samples_split': [2, 5, 10]})


best parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}



(B) Confusion Matrix
[[41  0  0]
 [ 0 13  0]
 [ 0  0 30]]


(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        41
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        30

    accuracy                           1.00        84
   macro avg       1.00      1.00      1.00        84
weighted avg       1.00      1.00      1.00        84


(E) The result after 5 times of train-test repetition:
best parameters for iteration1: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}
best parameters for iteration2: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}
best parameters for iteration3: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}
best parameters for iteration4: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}
best parameters for iteration5: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}


average accuracy: 0.9452, variance: 0.000658
average macro-average F1: 0.9268, variance: 0.001893
average weighted-average F1: 0.9434, variance: 0.000798



**************************************************************
(A) Classifier 3 - Base MLP
MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')


(B) Confusion Matrix
[[39  0  0]
 [20  0  0]
 [25  0  0]]


(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        39
      Gentoo       0.00      0.00      0.00        20
    Chinstap       0.00      0.00      0.00        25

    accuracy                           0.46        84
   macro avg       0.15      0.33      0.21        84
weighted avg       0.22      0.46      0.29        84


Base MLP Train-Test Repetition

=== Iteration 1 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[30  0  0]
 [18  0  0]
 [36  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.36      1.00      0.53        30
      Gentoo       0.00      0.00      0.00        18
    Chinstap       0.00      0.00      0.00        36

    accuracy                           0.36        84
   macro avg       0.12      0.33      0.18        84
weighted avg       0.13      0.36      0.19        84

=== Iteration 2 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[33  0  0]
 [20  0  0]
 [31  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.39      1.00      0.56        33
      Gentoo       0.00      0.00      0.00        20
    Chinstap       0.00      0.00      0.00        31

    accuracy                           0.39        84
   macro avg       0.13      0.33      0.19        84
weighted avg       0.15      0.39      0.22        84

=== Iteration 3 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[39  0  0]
 [15  0  0]
 [30  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        39
      Gentoo       0.00      0.00      0.00        15
    Chinstap       0.00      0.00      0.00        30

    accuracy                           0.46        84
   macro avg       0.15      0.33      0.21        84
weighted avg       0.22      0.46      0.29        84

=== Iteration 4 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[41  0  0]
 [15  0  0]
 [28  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.49      1.00      0.66        41
      Gentoo       0.00      0.00      0.00        15
    Chinstap       0.00      0.00      0.00        28

    accuracy                           0.49        84
   macro avg       0.16      0.33      0.22        84
weighted avg       0.24      0.49      0.32        84

=== Iteration 5 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[31  0  0]
 [20  0  0]
 [33  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.37      1.00      0.54        31
      Gentoo       0.00      0.00      0.00        20
    Chinstap       0.00      0.00      0.00        33

    accuracy                           0.37        84
   macro avg       0.12      0.33      0.18        84
weighted avg       0.14      0.37      0.20        84

(E) The result after 5 times of train-test repetition:
	The average accuracy / variance:  0.4143,  0.002744
	The average macro-average f1 score / variance:  0.1946,  0.000299
	The average weighted-average f1 score / variance:  0.2446,  0.002803


**************************************************************
(A) Classifier 4 - Top MLP
best parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[39  0  0]
 [ 2 18  0]
 [ 0  0 25]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.95      1.00      0.97        39
      Gentoo       1.00      0.90      0.95        20
    Chinstap       1.00      1.00      1.00        25

    accuracy                           0.98        84
   macro avg       0.98      0.97      0.97        84
weighted avg       0.98      0.98      0.98        84


Top MLP Train-Test Repetition

=== Iteration 1 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[41  0  0]
 [ 2 10  0]
 [ 0  0 31]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.95      1.00      0.98        41
      Gentoo       1.00      0.83      0.91        12
    Chinstap       1.00      1.00      1.00        31

    accuracy                           0.98        84
   macro avg       0.98      0.94      0.96        84
weighted avg       0.98      0.98      0.98        84

=== Iteration 2 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[41  0  0]
 [ 1 16  0]
 [ 0  0 26]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.98      1.00      0.99        41
      Gentoo       1.00      0.94      0.97        17
    Chinstap       1.00      1.00      1.00        26

    accuracy                           0.99        84
   macro avg       0.99      0.98      0.99        84
weighted avg       0.99      0.99      0.99        84

=== Iteration 3 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[35  0  0]
 [ 0 22  0]
 [ 0  0 27]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        35
      Gentoo       1.00      1.00      1.00        22
    Chinstap       1.00      1.00      1.00        27

    accuracy                           1.00        84
   macro avg       1.00      1.00      1.00        84
weighted avg       1.00      1.00      1.00        84

=== Iteration 4 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[40  0  0]
 [ 1 10  0]
 [ 0  0 33]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.98      1.00      0.99        40
      Gentoo       1.00      0.91      0.95        11
    Chinstap       1.00      1.00      1.00        33

    accuracy                           0.99        84
   macro avg       0.99      0.97      0.98        84
weighted avg       0.99      0.99      0.99        84

=== Iteration 5 === 
(A) Best Parameters: {'activation': 'relu', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[42  0  0]
 [ 1 15  0]
 [ 0  0 26]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.98      1.00      0.99        42
      Gentoo       1.00      0.94      0.97        16
    Chinstap       1.00      1.00      1.00        26

    accuracy                           0.99        84
   macro avg       0.99      0.98      0.99        84
weighted avg       0.99      0.99      0.99        84

(E) The result after 5 times of train-test repetition:
	The average accuracy / variance:  0.9881,  0.000057
	The average macro-average f1 score / variance:  0.9826,  0.000152
	The average weighted-average f1 score / variance:  0.9878,  0.000061


