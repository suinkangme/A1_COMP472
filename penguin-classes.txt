**************************************************************
(A) Classifier 1 - Base DT
DecisionTreeClassifier()


(B) Confusion Matrix
[[41  2  0]
 [ 0 18  1]
 [ 0  0 38]]


(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       1.00      0.95      0.98        43
      Gentoo       0.90      0.95      0.92        19
    Chinstap       0.97      1.00      0.99        38

    accuracy                           0.97       100
   macro avg       0.96      0.97      0.96       100
weighted avg       0.97      0.97      0.97       100


(E) The result after 5 times of train-test repetition:
average accuracy: 0.9640, variance: 0.000224
average macro-average F1: 0.9545, variance: 0.000249
average weighted-average F1: 0.9645, variance: 0.000222




**************************************************************
(A) Classifier 2 - Top DT
GridSearchCV(estimator=DecisionTreeClassifier(),
             param_grid={'criterion': ['gini', 'entropy'],
                         'max_depth': [None, 3, 5],
                         'min_samples_split': [2, 5, 10]})


best parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}



(B) Confusion Matrix
[[50  3  0]
 [ 0 15  0]
 [ 0  1 31]]


(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       1.00      0.94      0.97        53
   Chinstrap       0.79      1.00      0.88        15
      Gentoo       1.00      0.97      0.98        32

    accuracy                           0.96       100
   macro avg       0.93      0.97      0.95       100
weighted avg       0.97      0.96      0.96       100


(E) The result after 5 times of train-test repetition:
best parameters for iteration1: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}
best parameters for iteration2: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}
best parameters for iteration3: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}
best parameters for iteration4: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10}
best parameters for iteration5: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}


average accuracy: 0.9620, variance: 0.000176
average macro-average F1: 0.9571, variance: 0.000225
average weighted-average F1: 0.9620, variance: 0.000175



**************************************************************
(A) Classifier 3 - Base MLP
MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')


(B) Confusion Matrix
[[ 0  0 49]
 [ 0  0 27]
 [ 0  0 24]]


(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.00      0.00      0.00        49
      Gentoo       0.00      0.00      0.00        27
    Chinstap       0.24      1.00      0.39        24

    accuracy                           0.24       100
   macro avg       0.08      0.33      0.13       100
weighted avg       0.06      0.24      0.09       100


Base MLP Train-Test Repetition

=== Iteration 1 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[46  0  0]
 [19  0  0]
 [35  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        46
      Gentoo       0.00      0.00      0.00        19
    Chinstap       0.00      0.00      0.00        35

    accuracy                           0.46       100
   macro avg       0.15      0.33      0.21       100
weighted avg       0.21      0.46      0.29       100

=== Iteration 2 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[49  0  0]
 [18  0  0]
 [33  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.49      1.00      0.66        49
      Gentoo       0.00      0.00      0.00        18
    Chinstap       0.00      0.00      0.00        33

    accuracy                           0.49       100
   macro avg       0.16      0.33      0.22       100
weighted avg       0.24      0.49      0.32       100

=== Iteration 3 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[38  0  0]
 [20  0  0]
 [42  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.38      1.00      0.55        38
      Gentoo       0.00      0.00      0.00        20
    Chinstap       0.00      0.00      0.00        42

    accuracy                           0.38       100
   macro avg       0.13      0.33      0.18       100
weighted avg       0.14      0.38      0.21       100

=== Iteration 4 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[47  0  0]
 [19  0  0]
 [34  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.47      1.00      0.64        47
      Gentoo       0.00      0.00      0.00        19
    Chinstap       0.00      0.00      0.00        34

    accuracy                           0.47       100
   macro avg       0.16      0.33      0.21       100
weighted avg       0.22      0.47      0.30       100

=== Iteration 5 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[43  0  0]
 [15  0  0]
 [42  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.43      1.00      0.60        43
      Gentoo       0.00      0.00      0.00        15
    Chinstap       0.00      0.00      0.00        42

    accuracy                           0.43       100
   macro avg       0.14      0.33      0.20       100
weighted avg       0.18      0.43      0.26       100

(E) The result after 5 times of train-test repetition:
	The average accuracy / variance:  0.4460,  0.001464
	The average macro-average f1 score / variance:  0.2053,  0.000155
	The average weighted-average f1 score / variance:  0.2761,  0.001538


**************************************************************
(A) Classifier 4 - Top MLP
best parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[49  0  0]
 [ 1 26  0]
 [ 0  0 24]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.98      1.00      0.99        49
      Gentoo       1.00      0.96      0.98        27
    Chinstap       1.00      1.00      1.00        24

    accuracy                           0.99       100
   macro avg       0.99      0.99      0.99       100
weighted avg       0.99      0.99      0.99       100


Top MLP Train-Test Repetition

=== Iteration 1 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[36  0  0]
 [ 1 32  0]
 [ 0  0 31]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.97      1.00      0.99        36
      Gentoo       1.00      0.97      0.98        33
    Chinstap       1.00      1.00      1.00        31

    accuracy                           0.99       100
   macro avg       0.99      0.99      0.99       100
weighted avg       0.99      0.99      0.99       100

=== Iteration 2 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[43  0  0]
 [ 1 18  0]
 [ 0  0 38]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.98      1.00      0.99        43
      Gentoo       1.00      0.95      0.97        19
    Chinstap       1.00      1.00      1.00        38

    accuracy                           0.99       100
   macro avg       0.99      0.98      0.99       100
weighted avg       0.99      0.99      0.99       100

=== Iteration 3 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[50  0  0]
 [ 0 16  0]
 [ 0  0 34]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        50
      Gentoo       1.00      1.00      1.00        16
    Chinstap       1.00      1.00      1.00        34

    accuracy                           1.00       100
   macro avg       1.00      1.00      1.00       100
weighted avg       1.00      1.00      1.00       100

=== Iteration 4 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[49  0  0]
 [ 0 18  0]
 [ 0  0 33]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        49
      Gentoo       1.00      1.00      1.00        18
    Chinstap       1.00      1.00      1.00        33

    accuracy                           1.00       100
   macro avg       1.00      1.00      1.00       100
weighted avg       1.00      1.00      1.00       100

=== Iteration 5 === 
(A) Best Parameters: {'activation': 'relu', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[46  0  0]
 [ 0 20  0]
 [ 0  0 34]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        46
      Gentoo       1.00      1.00      1.00        20
    Chinstap       1.00      1.00      1.00        34

    accuracy                           1.00       100
   macro avg       1.00      1.00      1.00       100
weighted avg       1.00      1.00      1.00       100

(E) The result after 5 times of train-test repetition:
	The average accuracy / variance:  0.9960,  0.000024
	The average macro-average f1 score / variance:  0.9955,  0.000031
	The average weighted-average f1 score / variance:  0.9960,  0.000024


