**************************************************************
(A) Classifier 1 - Base DT
DecisionTreeClassifier()


(B) Confusion Matrix
[[35  2  0]
 [ 0 21  0]
 [ 0  1 41]]


(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       1.00      0.95      0.97        37
      Gentoo       0.88      1.00      0.93        21
    Chinstap       1.00      0.98      0.99        42

    accuracy                           0.97       100
   macro avg       0.96      0.97      0.96       100
weighted avg       0.97      0.97      0.97       100


(E) The result after 5 times of train-test repetition:
average accuracy: 0.968, variance: 9.600000000000017e-05
average macro-average F1: 0.9643858405690947, variance: 9.273540600405496e-05
average weighted-average F1: 0.9683834293141764, variance: 9.5930224261158e-05


**************************************************************
(A) Classifier 2 - Top DT
GridSearchCV(estimator=DecisionTreeClassifier(),
             param_grid={'criterion': ['gini', 'entropy'],
                         'max_depth': [None, 3, 5],
                         'min_samples_split': [2, 5, 10]})
best parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}



              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        48
   Chinstrap       0.91      1.00      0.95        21
      Gentoo       1.00      0.94      0.97        31

    accuracy                           0.98       100
   macro avg       0.97      0.98      0.97       100
weighted avg       0.98      0.98      0.98       100

confusion matrix
[[48  0  0]
 [ 0 21  0]
 [ 0  2 29]]



(E) The result after 5 times of train-test repetition:
best parameters for iteration1: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}
best parameters for iteration2: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}
best parameters for iteration3: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}
best parameters for iteration4: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}
best parameters for iteration5: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}
average accuracy: 0.96, variance: 4.000000000000007e-05
average macro-average F1: 0.9533505276846924, variance: 4.9673770418817884e-05
average weighted-average F1: 0.9604160476483026, variance: 3.588712198844457e-05



**************************************************************
(A) Classifier 3 - Base MLP
MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')


(B) Confusion Matrix
[[45  0  0]
 [20  0  0]
 [35  0  0]]


(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.45      1.00      0.62        45
      Gentoo       0.00      0.00      0.00        20
    Chinstap       0.00      0.00      0.00        35

    accuracy                           0.45       100
   macro avg       0.15      0.33      0.21       100
weighted avg       0.20      0.45      0.28       100


Base MLP Train-Test Repetition

=== Iteration 1 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[40  0  0]
 [19  0  0]
 [41  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.40      1.00      0.57        40
      Gentoo       0.00      0.00      0.00        19
    Chinstap       0.00      0.00      0.00        41

    accuracy                           0.40       100
   macro avg       0.13      0.33      0.19       100
weighted avg       0.16      0.40      0.23       100

=== Iteration 2 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[42  0  0]
 [19  0  0]
 [39  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.42      1.00      0.59        42
      Gentoo       0.00      0.00      0.00        19
    Chinstap       0.00      0.00      0.00        39

    accuracy                           0.42       100
   macro avg       0.14      0.33      0.20       100
weighted avg       0.18      0.42      0.25       100

=== Iteration 3 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[49  0  0]
 [19  0  0]
 [32  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.49      1.00      0.66        49
      Gentoo       0.00      0.00      0.00        19
    Chinstap       0.00      0.00      0.00        32

    accuracy                           0.49       100
   macro avg       0.16      0.33      0.22       100
weighted avg       0.24      0.49      0.32       100

=== Iteration 4 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[38  0  0]
 [25  0  0]
 [37  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.38      1.00      0.55        38
      Gentoo       0.00      0.00      0.00        25
    Chinstap       0.00      0.00      0.00        37

    accuracy                           0.38       100
   macro avg       0.13      0.33      0.18       100
weighted avg       0.14      0.38      0.21       100

=== Iteration 5 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[36  0  0]
 [24  0  0]
 [40  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.36      1.00      0.53        36
      Gentoo       0.00      0.00      0.00        24
    Chinstap       0.00      0.00      0.00        40

    accuracy                           0.36       100
   macro avg       0.12      0.33      0.18       100
weighted avg       0.13      0.36      0.19       100

(E) The result after 5 times of train-test repetition:
	The average accuracy / variance:  0.4100,  0.002000
	The average macro-average f1 score / variance:  0.1934,  0.000215
	The average weighted-average f1 score / variance:  0.2398,  0.002072


**************************************************************
(A) Classifier 4 - Top MLP
best parameters: {'activation': 'logistic', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[43  0  2]
 [20  0  0]
 [ 4  0 31]]
(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.64      0.96      0.77        45
      Gentoo       0.00      0.00      0.00        20
    Chinstap       0.94      0.89      0.91        35

    accuracy                           0.74       100
   macro avg       0.53      0.61      0.56       100
weighted avg       0.62      0.74      0.66       100


Top MLP Train-Test Repetition

=== Iteration 1 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[27  0 13]
 [17  0  2]
 [ 4  0 37]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.56      0.68      0.61        40
      Gentoo       0.00      0.00      0.00        19
    Chinstap       0.71      0.90      0.80        41

    accuracy                           0.64       100
   macro avg       0.42      0.53      0.47       100
weighted avg       0.52      0.64      0.57       100

=== Iteration 2 === 
(A) Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[36  0  0]
 [29  0  0]
 [35  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.36      1.00      0.53        36
      Gentoo       0.00      0.00      0.00        29
    Chinstap       0.00      0.00      0.00        35

    accuracy                           0.36       100
   macro avg       0.12      0.33      0.18       100
weighted avg       0.13      0.36      0.19       100

=== Iteration 3 === 
(A) Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[45  0  0]
 [24  0  0]
 [31  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.45      1.00      0.62        45
      Gentoo       0.00      0.00      0.00        24
    Chinstap       0.00      0.00      0.00        31

    accuracy                           0.45       100
   macro avg       0.15      0.33      0.21       100
weighted avg       0.20      0.45      0.28       100

=== Iteration 4 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[39  0  2]
 [22  0  0]
 [16  0 21]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.51      0.95      0.66        41
      Gentoo       0.00      0.00      0.00        22
    Chinstap       0.91      0.57      0.70        37

    accuracy                           0.60       100
   macro avg       0.47      0.51      0.45       100
weighted avg       0.55      0.60      0.53       100

=== Iteration 5 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[43  0  0]
 [20  0  0]
 [37  0  0]]

(C,D) Classification Report
              precision    recall  f1-score   support

      Adelie       0.43      1.00      0.60        43
      Gentoo       0.00      0.00      0.00        20
    Chinstap       0.00      0.00      0.00        37

    accuracy                           0.43       100
   macro avg       0.14      0.33      0.20       100
weighted avg       0.18      0.43      0.26       100

(E) The result after 5 times of train-test repetition:
	The average accuracy / variance:  0.4960,  0.011304
	The average macro-average f1 score / variance:  0.3015,  0.017253
	The average weighted-average f1 score / variance:  0.3660,  0.023806


