**************************************************************
(A) Classifier 1 - Base DT
DecisionTreeClassifier(max_depth=3)


(B) Confusion Matrix
[[136  47 226]
 [ 29 318  64]
 [134  88 212]]


(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.45      0.33      0.38       409
           M       0.70      0.77      0.74       411
           I       0.42      0.49      0.45       434

    accuracy                           0.53      1254
   macro avg       0.53      0.53      0.52      1254
weighted avg       0.52      0.53      0.52      1254


(E) The result after 5 times of train-test repetition:
average accuracy: 0.5349, variance: 0.000041
average macro-average F1: 0.4921, variance: 0.002538
average weighted-average F1: 0.4949, variance: 0.002293


**************************************************************
(A) Classifier 2 - Top DT
GridSearchCV(estimator=DecisionTreeClassifier(max_depth=3),
             param_grid={'criterion': ['gini', 'entropy'],
                         'max_depth': [None, 3, 5],
                         'min_samples_split': [2, 5, 10]})


best parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}



(B) Confusion Matrix
[[170  50 190]
 [ 42 300  66]
 [125  91 220]]


(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.50      0.41      0.46       410
           M       0.68      0.74      0.71       408
           I       0.46      0.50      0.48       436

    accuracy                           0.55      1254
   macro avg       0.55      0.55      0.55      1254
weighted avg       0.55      0.55      0.55      1254


(E) The result after 5 times of train-test repetition:
best parameters for iteration1: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2}
best parameters for iteration2: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}
best parameters for iteration3: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2}
best parameters for iteration4: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10}
best parameters for iteration5: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5}


average accuracy: 0.5547, variance: 0.000059
average macro-average F1: 0.5463, variance: 0.000025
average weighted-average F1: 0.5475, variance: 0.000037
**************************************************************
(A) Classifier 3 - Base MLP
MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[ 26  70 289]
 [  0 301  94]
 [ 27 113 334]]

(C, D) Classification Report
              precision    recall  f1-score   support

           F       0.49      0.07      0.12       385
           M       0.62      0.76      0.68       395
           I       0.47      0.70      0.56       474

    accuracy                           0.53      1254
   macro avg       0.53      0.51      0.45      1254
weighted avg       0.52      0.53      0.46      1254


Base MLP Train-Test Repetition

=== Iteration 1 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[  0  61 334]
 [  0 300 107]
 [  4 114 334]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       395
           M       0.63      0.74      0.68       407
           I       0.43      0.74      0.54       452

    accuracy                           0.51      1254
   macro avg       0.35      0.49      0.41      1254
weighted avg       0.36      0.51      0.42      1254

=== Iteration 2 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[ 16  68 313]
 [  0 307  85]
 [ 23 121 321]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.41      0.04      0.07       397
           M       0.62      0.78      0.69       392
           I       0.45      0.69      0.54       465

    accuracy                           0.51      1254
   macro avg       0.49      0.50      0.44      1254
weighted avg       0.49      0.51      0.44      1254

=== Iteration 3 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[ 58  53 247]
 [  2 334  81]
 [ 57 105 317]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.50      0.16      0.24       358
           M       0.68      0.80      0.73       417
           I       0.49      0.66      0.56       479

    accuracy                           0.57      1254
   macro avg       0.56      0.54      0.51      1254
weighted avg       0.56      0.57      0.53      1254

=== Iteration 4 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[ 30  71 281]
 [  0 329  80]
 [ 32  95 336]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.48      0.08      0.14       382
           M       0.66      0.80      0.73       409
           I       0.48      0.73      0.58       463

    accuracy                           0.55      1254
   macro avg       0.54      0.54      0.48      1254
weighted avg       0.54      0.55      0.49      1254

=== Iteration 5 === 
(A) MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              solver='sgd')

(B) Confusion Matrix
[[  0  58 344]
 [  0 317  90]
 [  0 102 343]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       402
           M       0.66      0.78      0.72       407
           I       0.44      0.77      0.56       445

    accuracy                           0.53      1254
   macro avg       0.37      0.52      0.43      1254
weighted avg       0.37      0.53      0.43      1254

(E) The result after 5 times of train-test repetition:
	The average accuracy / variance:  0.5330,  0.000535
	The average macro-average f1 score / variance:  0.4531,  0.001512
	The average weighted-average f1 score / variance:  0.4623,  0.001776


**************************************************************
(A) Classifier 4 - Top MLP
best parameters: {'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}

(B) Confusion Matrix
[[135  63 187]
 [ 24 318  53]
 [136  97 241]]

(C, D) Classification Report
              precision    recall  f1-score   support

           F       0.46      0.35      0.40       385
           M       0.67      0.81      0.73       395
           I       0.50      0.51      0.50       474

    accuracy                           0.55      1254
   macro avg       0.54      0.55      0.54      1254
weighted avg       0.54      0.55      0.54      1254


Top MLP Train-Test Repetition

=== Iteration 1 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'sgd'}

(B) Confusion Matrix
[[142  56 179]
 [ 29 341  45]
 [159  86 217]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.43      0.38      0.40       377
           M       0.71      0.82      0.76       415
           I       0.49      0.47      0.48       462

    accuracy                           0.56      1254
   macro avg       0.54      0.56      0.55      1254
weighted avg       0.54      0.56      0.55      1254

=== Iteration 2 === 
(A) Best Parameters: {'activation': 'relu', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[145  57 186]
 [ 27 316  64]
 [146  69 244]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.46      0.37      0.41       388
           M       0.71      0.78      0.74       407
           I       0.49      0.53      0.51       459

    accuracy                           0.56      1254
   macro avg       0.55      0.56      0.56      1254
weighted avg       0.55      0.56      0.56      1254

=== Iteration 3 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[147  48 202]
 [ 23 318  48]
 [134  86 248]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.48      0.37      0.42       397
           M       0.70      0.82      0.76       389
           I       0.50      0.53      0.51       468

    accuracy                           0.57      1254
   macro avg       0.56      0.57      0.56      1254
weighted avg       0.56      0.57      0.56      1254

=== Iteration 4 === 
(A) Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[136  47 222]
 [ 26 314  62]
 [126  66 255]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.47      0.34      0.39       405
           M       0.74      0.78      0.76       402
           I       0.47      0.57      0.52       447

    accuracy                           0.56      1254
   macro avg       0.56      0.56      0.56      1254
weighted avg       0.56      0.56      0.55      1254

=== Iteration 5 === 
(A) Best Parameters: {'activation': 'relu', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}

(B) Confusion Matrix
[[167  35 196]
 [ 39 285  65]
 [157  65 245]]

(C,D) Classification Report
              precision    recall  f1-score   support

           F       0.46      0.42      0.44       398
           M       0.74      0.73      0.74       389
           I       0.48      0.52      0.50       467

    accuracy                           0.56      1254
   macro avg       0.56      0.56      0.56      1254
weighted avg       0.56      0.56      0.56      1254

(E) The result after 5 times of train-test repetition:
	The average accuracy / variance:  0.5614,  0.000019
	The average macro-average f1 score / variance:  0.5563,  0.000028
	The average weighted-average f1 score / variance:  0.5547,  0.000010


